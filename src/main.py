# src/main.py
import time
import pandas as pd
import numpy as np
from transformers import pipeline
import csv
from datetime import datetime
from .config import *
from .embedder import BGEEmbedder
from .vector_db import DenseSparseIndex
from .reranker import CrossEncoderReranker
from .aggregator import aggregate_to_providers

# ì˜ë„ ë¶„ë¥˜ê¸° (Zero-shot)
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

# í‰ê°€ë¥¼ ìœ„í•œ ê³¨ë“œì…‹
EVAL_GROUND_TRUTH = {
    # "ì£¼ì°¨ê³µê°„ì´ ë„“ê³ , ì‹ ë¶€ëŒ€ê¸°ì‹¤ì´ ë„“ê³  ì±„ê´‘ì´ ì¢‹ì€ ê³³": [1199, 1269, 1135, 1030, 1031],
    # "í˜¸í…”ì—ì„œ ì‹ì„ ì˜¬ë¦¬ê³  ì—­ê³¼ ê°€ê¹Œìš´ ê³³" : [1003, 1025, 1109, 1112, 1107],
    # "ì±„í”Œí™€ì´ê³  ì‹ì‚¬ê°€ í›Œë¥­í•œ ê³³": [1008, 1111, 1209, 1210],
    "ì•¼ì™¸ ì›¨ë”©í™€ì— ì‹ëŒ€ê°€ ë§›ìˆëŠ” ê³³": [1066, 1133, 1216, 1191, 1163, 1113],
    # "ë‹¨ë…í™€ì— í•˜ê°ë™ì„ ì´ ì¢‹ì€ ê³³" : [1009, 1012, 1019, 1029, 1031],
}

# ì´ˆê¸° raw dataë¥¼ ë²¡í„°í™” í•  ë•Œ, í•œë²ˆë§Œ ì£¼ì„ì„ í’€ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
# def run_build_embeddings():
#     """
#     (ì´ë¯¸ ì™„ì„±ëœ í•¨ìˆ˜)
#     chromaDBì— ì ì¬í•  ë²¡í„° íŒŒì¼ ë§Œë“¤ê¸°
#     1) raw csv â†’ 2) parquet with vectors
#     """
#     embedder = BGEEmbedder()
#     embedder.build_vector_parquet(
#         input_csv_path=RAW_CSV_PATH,
#         output_parquet_path=PROCESSED_PARQUET_PATH,
#     )

def classifier_user_intent(query):
    """
    [Task 1] ìœ ì € ì¿¼ë¦¬ ë¶„ì„ (Target Aspect ì¶”ì¶œ)
    Zero-shot Classificationì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ì—ì„œ ê´€ë ¨ ì†ì„±ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print("\n" + "="*30 + "\n[Task 1] Intent Analysis\n" + "="*30)
    
    target_labels = ASPECT_COLUMNS[:7]  # ì„¤ì •ëœ ì£¼ìš” Aspectë“¤
    
    # 1) ëª¨ë¸ì„ í†µí•œ ì˜ë„ ë¶„ë¥˜ (ì‹¤ì œ ê°€ë™ ì‹œ ì£¼ì„ í•´ì œ)
    # clf_res = classifier(query, target_labels, multi_label=True)
    # relevant_aspects = [l for l, s in zip(clf_res['labels'], clf_res['scores']) if s > 0.5]
    
    # í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© (ë¶„ë¥˜ê¸° ì†ë„ê°€ ëŠë¦´ ê²½ìš°ë¥¼ ëŒ€ë¹„)
    relevant_aspects = ['hall_vibe', 'catering']  # ì˜ˆ: ë‹¨ë…í™€ì— í•˜ê°ë™ì„ ì´ ì¢‹ì€ ê³³
    
    num_query_aspects = len(relevant_aspects)
    
    # ë°©ì–´ ë¡œì§: ì¶”ì¶œëœ ì˜ë„ê°€ ì—†ì„ ê²½ìš°
    if num_query_aspects == 0:
        num_query_aspects = 1
        print("âš ï¸ ìœ ì € ì˜ë„ì—ì„œ ì¶”ì¶œëœ Aspectê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
    
    print(f"ğŸ¯ ìœ ì € ì˜ë„ ë¶„ì„ ê²°ê³¼: {relevant_aspects} (ì´ {num_query_aspects}ê°œ)")
    return relevant_aspects, num_query_aspects


def hybrid_retrieval(query, relevant_aspects, index_service, embedder, df):
    """
    [Task 2] Hybrid Search Stage
    ê° Aspectë³„ë¡œ Dense + Sparse ê²€ìƒ‰ í›„ RRFë¡œ í†µí•© í›„ë³´êµ° ì¸ì¶œ
    """
    
    print("\n" + "="*30 + "\n[Task 2] Hybrid Search (Recall)\n" + "="*30)
    

    all_candidates = []
    
    # 2) Aspectë³„ ë…ë¦½ ê²€ìƒ‰ ë£¨í”„
    for aspect in relevant_aspects:
        d_ranks, meta_map = index_service.get_dense_hits(query, aspect, embedder, n_results=50)
        s_ranks = index_service.get_sparse_hits(query, aspect, n_results=50)
        rrf_hits = index_service.calculate_rrf(d_ranks, s_ranks, meta_map)
        all_candidates.extend(rrf_hits)
        
    # --- [ìˆ˜ì •] ê²€ìƒ‰ëœ ì‹¤ì œ ì›ë¬¸ë“¤ ì¶œë ¥ ---
    print(f"\nğŸ” ì´ {len(all_candidates)}ê°œì˜ í›„ë³´ êµ¬ì ˆì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    print("-" * 80)
    print(f"{'Aspect':<15} | {'Venue Name':<15} | {'Review Snippet'}")
    print("-" * 80)
    
    for c in all_candidates:
        name = c.get('hall_name', 'Unknown')
        snippet = c['text'].replace('\n', ' ')[:50] # ì¶”ì²œ ê·¼ê±° ë³´ê³ ì‹¶ìœ¼ë©´ 50ë³´ë‹¤ ë” í¬ê²Œí•˜ì„¸ìš”.
        print(f"{c['aspect']:<15} | {name:<15} | {snippet}...")
    print("-" * 80)
        
    return all_candidates

def evaluate_retrieval(candidates, ground_truth_ids):
    #Recall: í›„ë³´êµ° ì•ˆì— ì •ë‹µ idê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    retrieved_ids = set([int(c['hall_id']) for c in candidates])
    hits = [gt_id for gt_id in ground_truth_ids if gt_id in retrieved_ids]
    
    recall = len(hits) / len(ground_truth_ids) if ground_truth_ids else 0
    print(f"\nğŸ“Š [Retrieval Evaluation] Recall@{len(candidates)}: {recall:.2%}")
    print(f"   (ì°¾ì€ ì •ë‹µ: {hits} / ì „ì²´ ì •ë‹µ: {ground_truth_ids})")
    return recall


def reranking(query, candidates, reranker):
    """
    [Task 3] Cross-Encoder Reranking Stage
    ì•ì„œ ì„ íƒëœ í›„ë³´êµ°ì„ ìœ ì € ì¿¼ë¦¬ì™€ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ì •ë°€ ì¬ìˆœìœ„í™”
    """
    print("\n" + "="*30 + "\n[Task 3] Cross-Encoder Reranking\n" + "="*30)
    
    # 1) ì •ë°€ ì¬ìˆœìœ„í™” ìˆ˜í–‰
    reranked_res = reranker.rerank(query, candidates)
    
    # 2) íŒŒì¼ ì €ì¥ì„ ìœ„í•œ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%H%M%S")
    log_filename = f"./data/logs/rerank_result_{timestamp}.csv"
    
    print(f"ğŸ’¾ ì „ì²´ ê²°ê³¼({len(reranked_res)}ê°œ)ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤: {log_filename}")
    
    # 3) íŒŒì¼ ì“°ê¸° ë° í„°ë¯¸ë„ ì „ì²´ ì¶œë ¥
    with open(log_filename, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=['hall_id', 'hall_name', 'aspect', 'cross_score', 'text'])
        writer.writeheader()
        
        print("\n" + "-"*100)
        print(f"{'Rank':<5} | {'Score':<8} | {'Aspect':<15} | {'Venue':<15} | {'Text'}")
        print("-" * 100)
        
        for i, res in enumerate(reranked_res):
            # íŒŒì¼ ì €ì¥
            writer.writerow({
                'hall_id': res['hall_id'],
                'hall_name': res.get('hall_name', ''),
                'aspect': res['aspect'],
                'cross_score': f"{res['cross_score']:.4f}",
                'text': res['text']
            })
            
            # í„°ë¯¸ë„ ì „ì²´ ì¶œë ¥ (í…ìŠ¤íŠ¸ëŠ” 60ìë§Œ)
            clean_text = res['text'].replace('\n', ' ')
            print(f"{i+1:<5} | {res['cross_score']:<8.4f} | {res['aspect']:<15} | {res.get('hall_name', 'N/A'):<15} | {clean_text[:500]}...")
            
    return reranked_res

def aggregate_results(reranked_res, num_query_aspects, df_processed):
    """ìµœì¢… ì¶”ì²œ ì—…ì²´ ì§‘ê³„"""
    
    print("\n" + "="*30 + "\n[Task 4] Final Aggregation\n" + "="*30)
    
    # 1) ì§‘ê³„ ìˆ˜í–‰ (aggregator.pyì˜ ë¡œì§ í˜¸ì¶œ)
    # ë°˜í™˜ê°’ì€ {hall_id: score} í˜•íƒœì˜ Seriesë¼ê³  ê°€ì •
    final_ranking_series = aggregate_to_providers(reranked_res, num_query_aspects)
    
    # 2) ë¡œê·¸ ì €ì¥
    timestamp = datetime.now().strftime("%H%M%S")
    log_filename = f"./data/logs/final_aggregation_{timestamp}.csv"
    
    final_log_data = []
    
    print(f"ğŸ’¾ ìµœì¢… ì§‘ê³„ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤: {log_filename}")
    print(f"\nğŸ† ìµœì¢… ì¶”ì²œ ì—…ì²´ TOP 20 (ìƒìœ„ ì—…ì²´ë¶€í„° ì •ë ¬)")
    print("-" * 60)
    
    # 3) ìƒìœ„ 20ê°œ ì¶”ì¶œ ë° ë£¨í”„
    # final_ranking_seriesê°€ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ìƒìœ„ 20ê°œë§Œ ìŠ¬ë¼ì´ì‹±
    top_20 = final_ranking_series.head(20)
    
    for rank, (h_id, score) in enumerate(top_20.items()):
        name_row = df_processed[df_processed[VENUE_ID_COL] == int(h_id)]
        name = name_row[HALL_NAME_COL].iloc[0] if not name_row.empty else "Unknown"
        
        print(f"  {rank+1:>2}ìœ„: {name:<20} (ID: {h_id:<5}) | í†µí•© ì ìˆ˜: {score:.4f}")
        
        # ë¡œê·¸ ë°ì´í„° ì¶•ì 
        final_log_data.append({
            'rank': rank + 1,
            'hall_id': h_id,
            'hall_name': name,
            'total_score': f"{score:.4f}"
        })
        
    # 4) CSV íŒŒì¼ ì €ì¥
    log_df = pd.DataFrame(final_log_data)
    log_df.to_csv(log_filename, index=False, encoding='utf-8-sig')
    
    print("-" * 60)
    print(f"âœ… ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {len(final_log_data)}ê°œ ì—…ì²´")
    
    return final_ranking_series
    
    
def calculate_metrics(top_ids, ground_truth, k=10):
    """
    ë‹¤ì–‘í•œ ê²€ìƒ‰ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° (MRR, Hit Rate, nDCG)
    """
    if not ground_truth:
        return {"mrr": 0.0, "hit_rate": 0.0, "ndcg": 0.0}

    # 1. MRR (Mean Reciprocal Rank)
    # ì •ë‹µ ì—…ì²´ë“¤ ì¤‘ ê°€ì¥ ë†’ì€ ìˆœìœ„ì— ìˆëŠ” ì—…ì²´ì˜ ì—­ìˆ˜ ìˆœìœ„ í•©ì˜ í‰ê· 
    rr_sum = 0
    for gt in ground_truth:
        if gt in top_ids:
            rank = top_ids.index(gt) + 1
            rr_sum += (1 / rank)
    mrr = rr_sum / len(ground_truth)

    # 2. Hit Rate @ K
    # ìƒìœ„ Kê°œ ê²°ê³¼ ì¤‘ì— ì •ë‹µì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì—¬ë¶€
    hits = [gt for gt in ground_truth if gt in top_ids[:k]]
    hit_rate = 1.0 if len(hits) > 0 else 0.0

    # 3. nDCG @ K (Normalized Discounted Cumulative Gain)
    # ì •ë‹µì´ ìƒë‹¨ì— ìˆì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬
    dcg = 0.0
    for i, _id in enumerate(top_ids[:k]):
        if _id in ground_truth:
            dcg += 1 / np.log2(i + 2)
            
    idcg = 0.0
    for i in range(min(len(ground_truth), k)):
        idcg += 1 / np.log2(i + 2)
        
    ndcg = dcg / idcg if idcg > 0 else 0.0

    return {"mrr": mrr, "hit_rate": hit_rate, "ndcg": ndcg}
    

if __name__ == "__main__":
    
    # 1) ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë”©
    df_processed = pd.read_parquet(PROCESSED_PARQUET_PATH)
    
    user_query = "ì•¼ì™¸ ì›¨ë”©í™€ì— ì‹ëŒ€ê°€ ë§›ìˆëŠ” ê³³"
    ground_truth = EVAL_GROUND_TRUTH.get(user_query, [])
    
    print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {user_query}")
    print(f"âœ… ì •ë‹µ ì—…ì²´ ë¦¬ìŠ¤íŠ¸: {ground_truth}")
    
    # 2) ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ ì´ˆê¸°í™”
    embedder = BGEEmbedder()
    index_service = DenseSparseIndex(df_processed)
    reranker = CrossEncoderReranker()

    
    # --- íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë³„ ì‹¤í–‰ ---
    # index_service.build_chroma_db() # 2) ChromaDB ì ì¬ (ìµœì´ˆ 1íšŒë§Œ ì£¼ì„ì„ í’€ê³  ì‹¤í–‰í•˜ì„¸ìš”.)
    relevant_aspects, num_query_aspects = classifier_user_intent(user_query)
    
    # 3) Retrieval (Aspecstë³„ Dense+Sparse+RRF)
    start_ret = time.time()
    candidates = hybrid_retrieval(user_query, relevant_aspects, index_service, embedder, df_processed)
    ret_latency = time.time() - start_ret
    print(f"â±ï¸ ê²€ìƒ‰ ì‹œê°„: {ret_latency:.2f}ì´ˆ")
    print(f"âœ… ê²€ìƒ‰ëœ ì´ í›„ë³´ ìˆ˜: {len(candidates)}ê°œ")
    
    # ì¤‘ê°„ í…ŒìŠ¤íŠ¸ í‰ê°€: ë¦¬íŠ¸ë¦¬ë²„ì˜ Recall
    print("\n" + "="*40)
    print("ğŸ“Š [Step 1] Retrieval(ì˜ˆì„ ) ì„±ëŠ¥ í‰ê°€")
    print("="*40)
    evaluate_retrieval(candidates, ground_truth)
    print(f"â±ï¸ Retrieval ì†Œìš” ì‹œê°„: {ret_latency:.4f}s")
    
    # 4) Reranking
    start_rerank = time.time()
    reranked_res = reranking(user_query, candidates, reranker)
    rerank_latency = time.time() - start_rerank
    print(f"â±ï¸ ì¬ì •ë ¬ ì‹œê°„: {rerank_latency:.2f}ì´ˆ")

    # 5) Aggregation
    start_agg = time.time()
    aggregate_results(reranked_res, num_query_aspects, df_processed)
    
    # ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    final_ranking_series = aggregate_to_providers(reranked_res, num_query_aspects)
    top_20_ids = [int(h_id) for h_id in final_ranking_series.head(20).index]
    agg_latency = time.time() - start_agg
    
    # 5) ì „ì²´ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = calculate_metrics(top_20_ids, ground_truth, k=10)
    recall_ret = evaluate_retrieval(candidates, ground_truth)

    # 6) ìµœì¢… í†µí•© ë¦¬í¬íŠ¸ ì¶œë ¥
    print("\n" + "="*50)
    print("ğŸ† ì‹œìŠ¤í…œ ìµœì¢… ì„±ëŠ¥ ê²€ì¦ ë¦¬í¬íŠ¸")
    print("="*50)
    
    print(f"ğŸ“Š [í’ˆì§ˆ ì§€í‘œ - ì •ë°€ë„ ë° ìˆœìœ„]")
    print(f"   - Recall@Ret      : {recall_ret:.4f} (í›„ë³´êµ° ë‚´ ì •ë‹µ ë¹„ìœ¨)")
    print(f"   - MRR             : {metrics['mrr']:.4f}")
    print(f"   - Hit Rate@10     : {metrics['hit_rate']:.0f}")
    print(f"   - nDCG@10         : {metrics['ndcg']:.4f}")
    
    print(f"\nâ±ï¸ [íš¨ìœ¨ ì§€í‘œ - ì§€ì—° ì‹œê°„]")
    print(f"   - Retrieval       : {ret_latency:.4f}s")
    print(f"   - Reranking       : {rerank_latency:.4f}s")
    print(f"   - Aggregation     : {agg_latency:.4f}s")
    print(f"   - Total Latency   : {ret_latency + rerank_latency + agg_latency:.4f}s")
    print("="*50)
    